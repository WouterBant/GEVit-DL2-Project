{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1BE9FJ74Z4",
        "outputId": "950ce4d8-1034-46cd-e3a7-8500d57ef880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GEVit-DL2-Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WouterBant/GEVit-DL2-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6Y9aRA74Z5",
        "outputId": "2b7231f8-0404-4465-917d-b4038cc1bf96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/GEVit-DL2-Project\n"
          ]
        }
      ],
      "source": [
        "%cd GEVit-DL2-Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0-ku1SYn74Z5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GYZLrQGB74Z5"
      },
      "outputs": [],
      "source": [
        "import os,sys\n",
        "g_selfatt_source =  os.path.join(os.getcwd(), '..')\n",
        "if g_selfatt_source not in sys.path:\n",
        "    sys.path.append(g_selfatt_source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXt7P_mn8KM1",
        "outputId": "cbf2d772-3c3f-497e-a571-b532833b0029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yPfj4x6Q74Z5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from g_selfatt.utils import num_params\n",
        "from torchvision import transforms\n",
        "from datasets import MNIST_rot\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jacE0BS774Z6",
        "outputId": "751c6ff7-b920-4de1-d3a2-1c609935456d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_mean = (0.1307,)\n",
        "data_stddev = (0.3081,)\n",
        "train_test = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=(-180, 180)),  # Random rotation between -15 to +15 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # Random horizontal flip with a probability of 0.5\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(data_mean, data_stddev)\n",
        "])\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(data_mean, data_stddev),\n",
        "    ]\n",
        ")\n",
        "train_set = MNIST_rot(root=\"../data\", stage=\"train\", download=True, transform=train_test, data_fraction=1, only_3_and_8=False)\n",
        "test_set = MNIST_rot(root=\"../data\", stage=\"test\", download=True, transform=transform_test, data_fraction=1, only_3_and_8=False)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-AAWEbPx74Z7"
      },
      "outputs": [],
      "source": [
        "# https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/11-vision-transformer.html\n",
        "def img_to_patch(x, patch_size, flatten_channels=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: Tensor representing the image of shape [B, C, H, W]\n",
        "        patch_size: Number of pixels per dimension of the patches (integer)\n",
        "        flatten_channels: If True, the patches will be returned in a flattened format\n",
        "                           as a feature vector instead of a image grid.\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    x = x.reshape(B, C, H // patch_size, patch_size, W // patch_size, patch_size)\n",
        "    x = x.permute(0, 2, 4, 1, 3, 5)  # [B, H', W', C, p_H, p_W]\n",
        "    x = x.flatten(1, 2)  # [B, H'*W', C, p_H, p_W]\n",
        "    if flatten_channels:\n",
        "        x = x.flatten(2, 4)  # [B, H'*W', C*p_H*p_W]\n",
        "    return x\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_dim, num_heads, dropout=0.0):\n",
        "        \"\"\"Attention Block.\n",
        "\n",
        "        Args:\n",
        "            embed_dim: Dimensionality of input and attention feature vectors\n",
        "            hidden_dim: Dimensionality of hidden layer in feed-forward network\n",
        "                         (usually 2-4x larger than embed_dim)\n",
        "            num_heads: Number of heads to use in the Multi-Head Attention block\n",
        "            dropout: Amount of dropout to apply in the feed-forward network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "        self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, embed_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp_x = self.layer_norm_1(x)\n",
        "        x = x + self.attn(inp_x, inp_x, inp_x)[0]\n",
        "        x = x + self.linear(self.layer_norm_2(x))\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        hidden_dim,\n",
        "        num_channels,\n",
        "        num_heads,\n",
        "        num_layers,\n",
        "        num_classes,\n",
        "        patch_size,\n",
        "        num_patches,\n",
        "        dropout=0.0,\n",
        "    ):\n",
        "        \"\"\"Vision Transformer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim: Dimensionality of the input feature vectors to the Transformer\n",
        "            hidden_dim: Dimensionality of the hidden layer in the feed-forward networks\n",
        "                         within the Transformer\n",
        "            num_channels: Number of channels of the input (3 for RGB)\n",
        "            num_heads: Number of heads to use in the Multi-Head Attention block\n",
        "            num_layers: Number of layers to use in the Transformer\n",
        "            num_classes: Number of classes to predict\n",
        "            patch_size: Number of pixels that the patches have per dimension\n",
        "            num_patches: Maximum number of patches an image can have\n",
        "            dropout: Amount of dropout to apply in the feed-forward network and\n",
        "                      on the input encoding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Layers/Networks\n",
        "        self.input_layer = nn.Linear(num_channels * (patch_size**2), embed_dim)\n",
        "        self.transformer = nn.Sequential(\n",
        "            *(AttentionBlock(embed_dim, hidden_dim, num_heads, dropout=dropout) for _ in range(num_layers))\n",
        "        )\n",
        "        self.mlp_head = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, num_classes))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Parameters/Embeddings\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 1 + num_patches, embed_dim))\n",
        "\n",
        "    def forward(self, x, output_cls=False):\n",
        "        # Preprocess input\n",
        "        x = img_to_patch(x, self.patch_size)\n",
        "        B, T, _ = x.shape\n",
        "        x = self.input_layer(x)\n",
        "\n",
        "        # Add CLS token and positional encoding\n",
        "        cls_token = self.cls_token.repeat(B, 1, 1)\n",
        "        x = torch.cat([cls_token, x], dim=1)\n",
        "        x = x + self.pos_embedding[:, : T + 1]\n",
        "\n",
        "        # Apply Transforrmer\n",
        "        x = self.dropout(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Perform classification prediction\n",
        "        cls = x[0]\n",
        "        if output_cls:\n",
        "            return cls\n",
        "\n",
        "        out = self.mlp_head(cls)\n",
        "        return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = VisionTransformer(embed_dim=64,\n",
        "                          hidden_dim=256,\n",
        "                          num_heads=4,\n",
        "                          num_layers=6,\n",
        "                          patch_size=4,\n",
        "                          num_channels=1,\n",
        "                          num_patches=49,\n",
        "                          num_classes=10,\n",
        "                          dropout=0.1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aJzKLwKV74Z7"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 0.0001)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-3)\n",
        "\n",
        "# scheduler for linear warmup of lr and then cosine decay\n",
        "# linear_warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1/10, end_factor=1.0, total_iters=10-1, last_epoch=-1, verbose=True)\n",
        "# cos_decay = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=200-10, eta_min=1e-5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71hFGlJI74Z7",
        "outputId": "0eae51e8-03a2-47aa-b944-386b91f3b587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters in the model: 305034\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of parameters in the model: {num_params(model)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJmRYUAi74Z8",
        "outputId": "fbaa4e58-3ec1-41ff-c93a-f3665d1f2f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 2.2753843929194195\n",
            "Epoch 2, Average Loss: 2.069302521174467\n",
            "Epoch 3, Average Loss: 1.9924414384214184\n",
            "Epoch 4, Average Loss: 1.9486270267752153\n",
            "Epoch 5, Average Loss: 1.8672694284704667\n",
            "Epoch 6, Average Loss: 1.6589191472983058\n",
            "Epoch 7, Average Loss: 1.5485421373874326\n",
            "Epoch 8, Average Loss: 1.484795647331431\n",
            "Epoch 9, Average Loss: 1.4429857670506345\n",
            "Epoch 10, Average Loss: 1.4099895410899874\n",
            "Epoch 11, Average Loss: 1.3983201693884935\n",
            "Epoch 12, Average Loss: 1.3716289604766458\n",
            "Epoch 13, Average Loss: 1.3461040748825557\n",
            "Epoch 14, Average Loss: 1.3346410174913044\n",
            "Epoch 15, Average Loss: 1.3168048632295826\n",
            "Epoch 16, Average Loss: 1.3108432474015634\n",
            "Epoch 17, Average Loss: 1.299592423288128\n",
            "Epoch 18, Average Loss: 1.2833537844162952\n",
            "Epoch 19, Average Loss: 1.278141312961337\n",
            "Epoch 20, Average Loss: 1.2725274049783055\n",
            "Epoch 21, Average Loss: 1.2627321662782114\n",
            "Epoch 22, Average Loss: 1.251509363138223\n",
            "Epoch 23, Average Loss: 1.232766849330709\n",
            "Epoch 24, Average Loss: 1.2264685766606391\n",
            "Epoch 25, Average Loss: 1.2291933086853992\n",
            "Epoch 26, Average Loss: 1.2250101943559284\n",
            "Epoch 27, Average Loss: 1.213423048393636\n",
            "Epoch 28, Average Loss: 1.2061593970165978\n",
            "Epoch 29, Average Loss: 1.193489277664619\n",
            "Epoch 30, Average Loss: 1.1852913883667957\n",
            "Epoch 31, Average Loss: 1.1766223628309709\n",
            "Epoch 32, Average Loss: 1.1831883478768264\n",
            "Epoch 33, Average Loss: 1.1664582347568078\n",
            "Epoch 34, Average Loss: 1.1673926771441592\n",
            "Epoch 35, Average Loss: 1.152124761026117\n",
            "Epoch 36, Average Loss: 1.1421175108680242\n",
            "Epoch 37, Average Loss: 1.1436939081059228\n",
            "Epoch 38, Average Loss: 1.124519558647011\n",
            "Epoch 39, Average Loss: 1.1263594898996474\n",
            "Epoch 40, Average Loss: 1.1260269118260733\n",
            "Epoch 41, Average Loss: 1.119013475466378\n",
            "Epoch 42, Average Loss: 1.1040400779699977\n",
            "Epoch 43, Average Loss: 1.0962803786313986\n",
            "Epoch 44, Average Loss: 1.0932113648969917\n",
            "Epoch 45, Average Loss: 1.0872414285623575\n",
            "Epoch 46, Average Loss: 1.0703709812103948\n",
            "Epoch 47, Average Loss: 1.0790048158621486\n",
            "Epoch 48, Average Loss: 1.0694964588442935\n",
            "Epoch 49, Average Loss: 1.0551597476005554\n",
            "Epoch 50, Average Loss: 1.0563478590566902\n",
            "Epoch 51, Average Loss: 1.040058442308933\n",
            "Epoch 52, Average Loss: 1.0381452494029757\n",
            "Epoch 53, Average Loss: 1.0367541826224025\n",
            "Epoch 54, Average Loss: 1.0154464222207855\n",
            "Epoch 55, Average Loss: 1.0210309398325184\n",
            "Epoch 56, Average Loss: 1.0331966552553298\n",
            "Epoch 57, Average Loss: 1.0024990205523334\n",
            "Epoch 58, Average Loss: 0.9908720715136468\n",
            "Epoch 59, Average Loss: 0.9937395543991765\n",
            "Epoch 60, Average Loss: 0.9980071571808827\n",
            "Epoch 61, Average Loss: 0.9775984860673735\n",
            "Epoch 62, Average Loss: 0.9908991818186603\n",
            "Epoch 63, Average Loss: 0.968477673922913\n",
            "Epoch 64, Average Loss: 0.9685545307171496\n",
            "Epoch 65, Average Loss: 0.9675091286248798\n",
            "Epoch 66, Average Loss: 0.9638679797136331\n",
            "Epoch 67, Average Loss: 0.9491691038578371\n",
            "Epoch 68, Average Loss: 0.9433712891385525\n",
            "Epoch 69, Average Loss: 0.9462333781809746\n",
            "Epoch 70, Average Loss: 0.9461108544204808\n",
            "Epoch 71, Average Loss: 0.9309785132166706\n",
            "Epoch 72, Average Loss: 0.9336517853072926\n",
            "Epoch 73, Average Loss: 0.9364423284047767\n",
            "Epoch 74, Average Loss: 0.9125574532943436\n",
            "Epoch 75, Average Loss: 0.9084556781792943\n",
            "Epoch 76, Average Loss: 0.9113685043552254\n",
            "Epoch 77, Average Loss: 0.8966778743116162\n",
            "Epoch 78, Average Loss: 0.897763608377191\n",
            "Epoch 79, Average Loss: 0.8939923530892481\n",
            "Epoch 80, Average Loss: 0.8859336511998237\n",
            "Epoch 81, Average Loss: 0.8817349423336077\n",
            "Epoch 82, Average Loss: 0.8812369078020507\n",
            "Epoch 83, Average Loss: 0.87529441072971\n",
            "Epoch 84, Average Loss: 0.855982694444777\n",
            "Epoch 85, Average Loss: 0.8665704002863244\n",
            "Epoch 86, Average Loss: 0.8510019828247118\n",
            "Epoch 87, Average Loss: 0.851521844350839\n",
            "Epoch 88, Average Loss: 0.8509310778183273\n",
            "Epoch 89, Average Loss: 0.8428006685232814\n",
            "Epoch 90, Average Loss: 0.8384799331049376\n",
            "Epoch 91, Average Loss: 0.8440909046161024\n",
            "Epoch 92, Average Loss: 0.8326388401321217\n",
            "Epoch 93, Average Loss: 0.8227579005156891\n",
            "Epoch 94, Average Loss: 0.8118989807140978\n",
            "Epoch 95, Average Loss: 0.8070941899396196\n",
            "Epoch 96, Average Loss: 0.8129196589506125\n",
            "Epoch 97, Average Loss: 0.818301831619649\n",
            "Epoch 98, Average Loss: 0.7986477232432063\n",
            "Epoch 99, Average Loss: 0.8061367477042766\n",
            "Epoch 100, Average Loss: 0.7954880210417735\n",
            "Epoch 101, Average Loss: 0.790009245842318\n",
            "Epoch 102, Average Loss: 0.8037527844875674\n",
            "Epoch 103, Average Loss: 0.7887195559996593\n",
            "Epoch 104, Average Loss: 0.784180081343349\n",
            "Epoch 105, Average Loss: 0.7794115799891798\n",
            "Epoch 106, Average Loss: 0.7788183674027648\n",
            "Epoch 107, Average Loss: 0.7779451563388486\n",
            "Epoch 108, Average Loss: 0.7765153480481498\n",
            "Epoch 109, Average Loss: 0.7714682462849195\n",
            "Epoch 110, Average Loss: 0.7652352686169781\n",
            "Epoch 111, Average Loss: 0.7517032381854479\n",
            "Epoch 112, Average Loss: 0.766294591034515\n",
            "Epoch 113, Average Loss: 0.7534724941736535\n",
            "Epoch 114, Average Loss: 0.7551616377468351\n",
            "Epoch 115, Average Loss: 0.7460199232342877\n",
            "Epoch 116, Average Loss: 0.7485875540141818\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(200):\n",
        "    losses = []\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to device\n",
        "        optimizer.zero_grad()\n",
        "        out = model(inputs)\n",
        "        loss = criterion(out, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update weights\n",
        "        losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {sum(losses)/len(losses)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYeDTZ0RAaYA"
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Disable gradient calculation during inference\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to device\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d885f5faea946e5b0b4e5891367ce6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfc06f4e5e194aebbf5f4627e13e1e24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/94.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "\n",
        "# https://huggingface.co/1aurent/resnet50.tiatoolbox-pcam/\n",
        "# get example histology image\n",
        "img = Image.open(\n",
        "  urlopen(\n",
        "    \"https://github.com/owkin/HistoSSLscaling/raw/main/assets/example.tif\"\n",
        "  )\n",
        ")\n",
        "\n",
        "# load model from the hub\n",
        "model = timm.create_model(\n",
        "  model_name=\"hf-hub:1aurent/resnet50.tiatoolbox-pcam\",\n",
        "  pretrained=True,\n",
        ").eval()\n",
        "\n",
        "# get model specific transforms (normalization, resize)\n",
        "data_config = timm.data.resolve_model_data_config(model)\n",
        "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
        "\n",
        "data = transforms(img).unsqueeze(0) # input is a (batch_size, num_channels, img_size, img_size) shaped tensor\n",
        "output = model(data)  # output is a (batch_size, num_features) shaped tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              ")"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers_before_last_linear = nn.Sequential(*list(model.children())[:-1])\n",
        "layers_before_last_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'generator' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
          ]
        }
      ],
      "source": [
        "model.\n",
        "fc = nn.Sequential(*list(model.fc.children())[:-1], new_layer, nn.ReLU(), nn.Linear(2048, 2)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Module.children of Linear(in_features=2048, out_features=2, bias=True)>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fc.children"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total length of the dataset: 32768\n",
            "Reduced length of the dataset: 163\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tvtf\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from datasets import MNIST_rot, PCam\n",
        "from train_vit import VisionTransformer\n",
        "\n",
        "from helpers import timeit\n",
        "data_mean = (0.701, 0.538, 0.692)\n",
        "data_stddev = (0.235, 0.277, 0.213)\n",
        "# transform_train = tvtf.Compose([\n",
        "#     tvtf.((3, 224, 224)),\n",
        "#     tvtf.RandomRotation(degrees=(-180, 180)),  # random rotation\n",
        "#     tvtf.RandomHorizontalFlip(),  # random horizontal flip with a probability of 0.5\n",
        "#     tvtf.RandomVerticalFlip(),\n",
        "#     tvtf.ToTensor(),\n",
        "#     tvtf.Normalize(data_mean, data_stddev)\n",
        "# ])\n",
        "# transform_test = tvtf.Compose(\n",
        "#     [\n",
        "#         tvtf.Resize(224),\n",
        "#         tvtf.ToTensor(),\n",
        "#     ]\n",
        "# )\n",
        "data_mean = [0., 0., 0.]  # Your mean values\n",
        "data_stddev = [1., 1., 1.]  # Your standard deviation values\n",
        "\n",
        "# Define the transformation pipeline\n",
        "transform_test = tvtf.Compose([\n",
        "    tvtf.Resize(96, interpolation=tvtf.InterpolationMode.BICUBIC),  # Resize the image to 96x96 using bicubic interpolation\n",
        "    tvtf.CenterCrop(96),  # Center crop the image to 96x96\n",
        "    tvtf.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    tvtf.Normalize(mean=data_mean, std=data_stddev)  # Normalize the tensor\n",
        "])\n",
        "\n",
        "train_set = PCam(root=\"../data\", train=True, download=True, transform=transform_train)\n",
        "validation_set = PCam(root=\"../data\", train=False, valid=True, download=True, transform=transform_test, data_fraction=0.005)\n",
        "test_set = PCam(root=\"../data\", train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    validation_set,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")\n",
        "img_loader = torch.utils.data.DataLoader(  # single element for visualization purposes\n",
        "    test_set,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=96, interpolation=bicubic, max_size=None, antialias=warn)\n",
              "    CenterCrop(size=[96, 96])\n",
              "    ToTensor()\n",
              "    Normalize(mean=tensor([0., 0., 0.]), std=tensor([1., 1., 1.]))\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/home/wouter/miniconda3/envs/myenv/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/home/wouter/miniconda3/envs/myenv/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "  0%|          | 0/2 [00:05<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89.0625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = total = 0\n",
        "with torch.no_grad():  # disable gradient calculation during inference\n",
        "    for inputs, labels in tqdm(val_loader):\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        test_acc = 100 * correct / total\n",
        "        print(test_acc)\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
