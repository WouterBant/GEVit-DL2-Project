{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "g_selfatt_source =  os.path.join(os.getcwd(), '..')\n",
    "if g_selfatt_source not in sys.path:\n",
    "    sys.path.append(g_selfatt_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import g_selfatt.groups as groups\n",
    "import torch\n",
    "import models\n",
    "from g_selfatt.utils import num_params\n",
    "import torch\n",
    "import torchvision\n",
    "from datasets import MNIST_rot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import models\n",
    "import torch\n",
    "import g_selfatt.groups as groups\n",
    "import models\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['group._identity', 'group._elements', 'group._relative_positions', 'lifting_self_attention.row_indices', 'lifting_self_attention.col_indices', 'lifting_self_attention.group._identity', 'lifting_self_attention.group._elements', 'lifting_self_attention.group._relative_positions', 'lifting_self_attention.row_embedding.0.weight', 'lifting_self_attention.row_embedding.0.bias', 'lifting_self_attention.row_embedding.1.layer_norm.weight', 'lifting_self_attention.row_embedding.1.layer_norm.bias', 'lifting_self_attention.row_embedding.3.weight', 'lifting_self_attention.row_embedding.3.bias', 'lifting_self_attention.col_embedding.0.weight', 'lifting_self_attention.col_embedding.0.bias', 'lifting_self_attention.col_embedding.1.layer_norm.weight', 'lifting_self_attention.col_embedding.1.layer_norm.bias', 'lifting_self_attention.col_embedding.3.weight', 'lifting_self_attention.col_embedding.3.bias', 'lifting_self_attention.query.weight', 'lifting_self_attention.query.bias', 'lifting_self_attention.key.weight', 'lifting_self_attention.key.bias', 'lifting_self_attention.value.weight', 'lifting_self_attention.value.bias', 'lifting_self_attention.wout.weight', 'lifting_self_attention.wout.bias', 'lifting_normalization.layer_norm.weight', 'lifting_normalization.layer_norm.bias', 'transformer.0.attention.0.layer_norm.weight', 'transformer.0.attention.0.layer_norm.bias', 'transformer.0.attention.2.row_indices', 'transformer.0.attention.2.col_indices', 'transformer.0.attention.2.g_indices', 'transformer.0.attention.2.group._identity', 'transformer.0.attention.2.group._elements', 'transformer.0.attention.2.group._relative_positions', 'transformer.0.attention.2.row_embedding.0.weight', 'transformer.0.attention.2.row_embedding.0.bias', 'transformer.0.attention.2.row_embedding.1.layer_norm.weight', 'transformer.0.attention.2.row_embedding.1.layer_norm.bias', 'transformer.0.attention.2.row_embedding.3.weight', 'transformer.0.attention.2.row_embedding.3.bias', 'transformer.0.attention.2.col_embedding.0.weight', 'transformer.0.attention.2.col_embedding.0.bias', 'transformer.0.attention.2.col_embedding.1.layer_norm.weight', 'transformer.0.attention.2.col_embedding.1.layer_norm.bias', 'transformer.0.attention.2.col_embedding.3.weight', 'transformer.0.attention.2.col_embedding.3.bias', 'transformer.0.attention.2.group_embedding.weight', 'transformer.0.attention.2.query.weight', 'transformer.0.attention.2.query.bias', 'transformer.0.attention.2.key.weight', 'transformer.0.attention.2.key.bias', 'transformer.0.attention.2.value.weight', 'transformer.0.attention.2.value.bias', 'transformer.0.attention.2.wout.weight', 'transformer.0.attention.2.wout.bias', 'transformer.0.attention.3.layer_norm.weight', 'transformer.0.attention.3.layer_norm.bias', 'transformer.0.mlp.0.weight', 'transformer.0.mlp.0.bias', 'transformer.0.mlp.1.layer_norm.weight', 'transformer.0.mlp.1.layer_norm.bias', 'transformer.0.mlp.3.weight', 'transformer.0.mlp.3.bias', 'transformer.0.mlp.4.layer_norm.weight', 'transformer.0.mlp.4.layer_norm.bias', 'transformer.1.attention.0.layer_norm.weight', 'transformer.1.attention.0.layer_norm.bias', 'transformer.1.attention.2.row_indices', 'transformer.1.attention.2.col_indices', 'transformer.1.attention.2.g_indices', 'transformer.1.attention.2.group._identity', 'transformer.1.attention.2.group._elements', 'transformer.1.attention.2.group._relative_positions', 'transformer.1.attention.2.row_embedding.0.weight', 'transformer.1.attention.2.row_embedding.0.bias', 'transformer.1.attention.2.row_embedding.1.layer_norm.weight', 'transformer.1.attention.2.row_embedding.1.layer_norm.bias', 'transformer.1.attention.2.row_embedding.3.weight', 'transformer.1.attention.2.row_embedding.3.bias', 'transformer.1.attention.2.col_embedding.0.weight', 'transformer.1.attention.2.col_embedding.0.bias', 'transformer.1.attention.2.col_embedding.1.layer_norm.weight', 'transformer.1.attention.2.col_embedding.1.layer_norm.bias', 'transformer.1.attention.2.col_embedding.3.weight', 'transformer.1.attention.2.col_embedding.3.bias', 'transformer.1.attention.2.group_embedding.weight', 'transformer.1.attention.2.query.weight', 'transformer.1.attention.2.query.bias', 'transformer.1.attention.2.key.weight', 'transformer.1.attention.2.key.bias', 'transformer.1.attention.2.value.weight', 'transformer.1.attention.2.value.bias', 'transformer.1.attention.2.wout.weight', 'transformer.1.attention.2.wout.bias', 'transformer.1.attention.3.layer_norm.weight', 'transformer.1.attention.3.layer_norm.bias', 'transformer.1.mlp.0.weight', 'transformer.1.mlp.0.bias', 'transformer.1.mlp.1.layer_norm.weight', 'transformer.1.mlp.1.layer_norm.bias', 'transformer.1.mlp.3.weight', 'transformer.1.mlp.3.bias', 'transformer.1.mlp.4.layer_norm.weight', 'transformer.1.mlp.4.layer_norm.bias', 'transformer.3.attention.0.layer_norm.weight', 'transformer.3.attention.0.layer_norm.bias', 'transformer.3.attention.2.row_indices', 'transformer.3.attention.2.col_indices', 'transformer.3.attention.2.g_indices', 'transformer.3.attention.2.group._identity', 'transformer.3.attention.2.group._elements', 'transformer.3.attention.2.group._relative_positions', 'transformer.3.attention.2.row_embedding.0.weight', 'transformer.3.attention.2.row_embedding.0.bias', 'transformer.3.attention.2.row_embedding.1.layer_norm.weight', 'transformer.3.attention.2.row_embedding.1.layer_norm.bias', 'transformer.3.attention.2.row_embedding.3.weight', 'transformer.3.attention.2.row_embedding.3.bias', 'transformer.3.attention.2.col_embedding.0.weight', 'transformer.3.attention.2.col_embedding.0.bias', 'transformer.3.attention.2.col_embedding.1.layer_norm.weight', 'transformer.3.attention.2.col_embedding.1.layer_norm.bias', 'transformer.3.attention.2.col_embedding.3.weight', 'transformer.3.attention.2.col_embedding.3.bias', 'transformer.3.attention.2.group_embedding.weight', 'transformer.3.attention.2.query.weight', 'transformer.3.attention.2.query.bias', 'transformer.3.attention.2.key.weight', 'transformer.3.attention.2.key.bias', 'transformer.3.attention.2.value.weight', 'transformer.3.attention.2.value.bias', 'transformer.3.attention.2.wout.weight', 'transformer.3.attention.2.wout.bias', 'transformer.3.attention.3.layer_norm.weight', 'transformer.3.attention.3.layer_norm.bias', 'transformer.3.mlp.0.weight', 'transformer.3.mlp.0.bias', 'transformer.3.mlp.1.layer_norm.weight', 'transformer.3.mlp.1.layer_norm.bias', 'transformer.3.mlp.3.weight', 'transformer.3.mlp.3.bias', 'transformer.3.mlp.4.layer_norm.weight', 'transformer.3.mlp.4.layer_norm.bias', 'transformer.4.attention.0.layer_norm.weight', 'transformer.4.attention.0.layer_norm.bias', 'transformer.4.attention.2.row_indices', 'transformer.4.attention.2.col_indices', 'transformer.4.attention.2.g_indices', 'transformer.4.attention.2.group._identity', 'transformer.4.attention.2.group._elements', 'transformer.4.attention.2.group._relative_positions', 'transformer.4.attention.2.row_embedding.0.weight', 'transformer.4.attention.2.row_embedding.0.bias', 'transformer.4.attention.2.row_embedding.1.layer_norm.weight', 'transformer.4.attention.2.row_embedding.1.layer_norm.bias', 'transformer.4.attention.2.row_embedding.3.weight', 'transformer.4.attention.2.row_embedding.3.bias', 'transformer.4.attention.2.col_embedding.0.weight', 'transformer.4.attention.2.col_embedding.0.bias', 'transformer.4.attention.2.col_embedding.1.layer_norm.weight', 'transformer.4.attention.2.col_embedding.1.layer_norm.bias', 'transformer.4.attention.2.col_embedding.3.weight', 'transformer.4.attention.2.col_embedding.3.bias', 'transformer.4.attention.2.group_embedding.weight', 'transformer.4.attention.2.query.weight', 'transformer.4.attention.2.query.bias', 'transformer.4.attention.2.key.weight', 'transformer.4.attention.2.key.bias', 'transformer.4.attention.2.value.weight', 'transformer.4.attention.2.value.bias', 'transformer.4.attention.2.wout.weight', 'transformer.4.attention.2.wout.bias', 'transformer.4.attention.3.layer_norm.weight', 'transformer.4.attention.3.layer_norm.bias', 'transformer.4.mlp.0.weight', 'transformer.4.mlp.0.bias', 'transformer.4.mlp.1.layer_norm.weight', 'transformer.4.mlp.1.layer_norm.bias', 'transformer.4.mlp.3.weight', 'transformer.4.mlp.3.bias', 'transformer.4.mlp.4.layer_norm.weight', 'transformer.4.mlp.4.layer_norm.bias', 'transformer.5.attention.0.layer_norm.weight', 'transformer.5.attention.0.layer_norm.bias', 'transformer.5.attention.2.row_indices', 'transformer.5.attention.2.col_indices', 'transformer.5.attention.2.g_indices', 'transformer.5.attention.2.group._identity', 'transformer.5.attention.2.group._elements', 'transformer.5.attention.2.group._relative_positions', 'transformer.5.attention.2.row_embedding.0.weight', 'transformer.5.attention.2.row_embedding.0.bias', 'transformer.5.attention.2.row_embedding.1.layer_norm.weight', 'transformer.5.attention.2.row_embedding.1.layer_norm.bias', 'transformer.5.attention.2.row_embedding.3.weight', 'transformer.5.attention.2.row_embedding.3.bias', 'transformer.5.attention.2.col_embedding.0.weight', 'transformer.5.attention.2.col_embedding.0.bias', 'transformer.5.attention.2.col_embedding.1.layer_norm.weight', 'transformer.5.attention.2.col_embedding.1.layer_norm.bias', 'transformer.5.attention.2.col_embedding.3.weight', 'transformer.5.attention.2.col_embedding.3.bias', 'transformer.5.attention.2.group_embedding.weight', 'transformer.5.attention.2.query.weight', 'transformer.5.attention.2.query.bias', 'transformer.5.attention.2.key.weight', 'transformer.5.attention.2.key.bias', 'transformer.5.attention.2.value.weight', 'transformer.5.attention.2.value.bias', 'transformer.5.attention.2.wout.weight', 'transformer.5.attention.2.wout.bias', 'transformer.5.attention.3.layer_norm.weight', 'transformer.5.attention.3.layer_norm.bias', 'transformer.5.mlp.0.weight', 'transformer.5.mlp.0.bias', 'transformer.5.mlp.1.layer_norm.weight', 'transformer.5.mlp.1.layer_norm.bias', 'transformer.5.mlp.3.weight', 'transformer.5.mlp.3.bias', 'transformer.5.mlp.4.layer_norm.weight', 'transformer.5.mlp.4.layer_norm.bias', 'transformer.6.weight'], unexpected_keys=['module.group._identity', 'module.group._elements', 'module.group._relative_positions', 'module.lifting_self_attention.row_indices', 'module.lifting_self_attention.col_indices', 'module.lifting_self_attention.group._identity', 'module.lifting_self_attention.group._elements', 'module.lifting_self_attention.group._relative_positions', 'module.lifting_self_attention.row_embedding.0.weight', 'module.lifting_self_attention.row_embedding.0.bias', 'module.lifting_self_attention.row_embedding.1.layer_norm.weight', 'module.lifting_self_attention.row_embedding.1.layer_norm.bias', 'module.lifting_self_attention.row_embedding.3.weight', 'module.lifting_self_attention.row_embedding.3.bias', 'module.lifting_self_attention.col_embedding.0.weight', 'module.lifting_self_attention.col_embedding.0.bias', 'module.lifting_self_attention.col_embedding.1.layer_norm.weight', 'module.lifting_self_attention.col_embedding.1.layer_norm.bias', 'module.lifting_self_attention.col_embedding.3.weight', 'module.lifting_self_attention.col_embedding.3.bias', 'module.lifting_self_attention.query.weight', 'module.lifting_self_attention.query.bias', 'module.lifting_self_attention.key.weight', 'module.lifting_self_attention.key.bias', 'module.lifting_self_attention.value.weight', 'module.lifting_self_attention.value.bias', 'module.lifting_self_attention.wout.weight', 'module.lifting_self_attention.wout.bias', 'module.lifting_normalization.layer_norm.weight', 'module.lifting_normalization.layer_norm.bias', 'module.transformer.0.attention.0.layer_norm.weight', 'module.transformer.0.attention.0.layer_norm.bias', 'module.transformer.0.attention.2.row_indices', 'module.transformer.0.attention.2.col_indices', 'module.transformer.0.attention.2.g_indices', 'module.transformer.0.attention.2.group._identity', 'module.transformer.0.attention.2.group._elements', 'module.transformer.0.attention.2.group._relative_positions', 'module.transformer.0.attention.2.row_embedding.0.weight', 'module.transformer.0.attention.2.row_embedding.0.bias', 'module.transformer.0.attention.2.row_embedding.1.layer_norm.weight', 'module.transformer.0.attention.2.row_embedding.1.layer_norm.bias', 'module.transformer.0.attention.2.row_embedding.3.weight', 'module.transformer.0.attention.2.row_embedding.3.bias', 'module.transformer.0.attention.2.col_embedding.0.weight', 'module.transformer.0.attention.2.col_embedding.0.bias', 'module.transformer.0.attention.2.col_embedding.1.layer_norm.weight', 'module.transformer.0.attention.2.col_embedding.1.layer_norm.bias', 'module.transformer.0.attention.2.col_embedding.3.weight', 'module.transformer.0.attention.2.col_embedding.3.bias', 'module.transformer.0.attention.2.group_embedding.weight', 'module.transformer.0.attention.2.query.weight', 'module.transformer.0.attention.2.query.bias', 'module.transformer.0.attention.2.key.weight', 'module.transformer.0.attention.2.key.bias', 'module.transformer.0.attention.2.value.weight', 'module.transformer.0.attention.2.value.bias', 'module.transformer.0.attention.2.wout.weight', 'module.transformer.0.attention.2.wout.bias', 'module.transformer.0.attention.3.layer_norm.weight', 'module.transformer.0.attention.3.layer_norm.bias', 'module.transformer.0.mlp.0.weight', 'module.transformer.0.mlp.0.bias', 'module.transformer.0.mlp.1.layer_norm.weight', 'module.transformer.0.mlp.1.layer_norm.bias', 'module.transformer.0.mlp.3.weight', 'module.transformer.0.mlp.3.bias', 'module.transformer.0.mlp.4.layer_norm.weight', 'module.transformer.0.mlp.4.layer_norm.bias', 'module.transformer.1.attention.0.layer_norm.weight', 'module.transformer.1.attention.0.layer_norm.bias', 'module.transformer.1.attention.2.row_indices', 'module.transformer.1.attention.2.col_indices', 'module.transformer.1.attention.2.g_indices', 'module.transformer.1.attention.2.group._identity', 'module.transformer.1.attention.2.group._elements', 'module.transformer.1.attention.2.group._relative_positions', 'module.transformer.1.attention.2.row_embedding.0.weight', 'module.transformer.1.attention.2.row_embedding.0.bias', 'module.transformer.1.attention.2.row_embedding.1.layer_norm.weight', 'module.transformer.1.attention.2.row_embedding.1.layer_norm.bias', 'module.transformer.1.attention.2.row_embedding.3.weight', 'module.transformer.1.attention.2.row_embedding.3.bias', 'module.transformer.1.attention.2.col_embedding.0.weight', 'module.transformer.1.attention.2.col_embedding.0.bias', 'module.transformer.1.attention.2.col_embedding.1.layer_norm.weight', 'module.transformer.1.attention.2.col_embedding.1.layer_norm.bias', 'module.transformer.1.attention.2.col_embedding.3.weight', 'module.transformer.1.attention.2.col_embedding.3.bias', 'module.transformer.1.attention.2.group_embedding.weight', 'module.transformer.1.attention.2.query.weight', 'module.transformer.1.attention.2.query.bias', 'module.transformer.1.attention.2.key.weight', 'module.transformer.1.attention.2.key.bias', 'module.transformer.1.attention.2.value.weight', 'module.transformer.1.attention.2.value.bias', 'module.transformer.1.attention.2.wout.weight', 'module.transformer.1.attention.2.wout.bias', 'module.transformer.1.attention.3.layer_norm.weight', 'module.transformer.1.attention.3.layer_norm.bias', 'module.transformer.1.mlp.0.weight', 'module.transformer.1.mlp.0.bias', 'module.transformer.1.mlp.1.layer_norm.weight', 'module.transformer.1.mlp.1.layer_norm.bias', 'module.transformer.1.mlp.3.weight', 'module.transformer.1.mlp.3.bias', 'module.transformer.1.mlp.4.layer_norm.weight', 'module.transformer.1.mlp.4.layer_norm.bias', 'module.transformer.3.attention.0.layer_norm.weight', 'module.transformer.3.attention.0.layer_norm.bias', 'module.transformer.3.attention.2.row_indices', 'module.transformer.3.attention.2.col_indices', 'module.transformer.3.attention.2.g_indices', 'module.transformer.3.attention.2.group._identity', 'module.transformer.3.attention.2.group._elements', 'module.transformer.3.attention.2.group._relative_positions', 'module.transformer.3.attention.2.row_embedding.0.weight', 'module.transformer.3.attention.2.row_embedding.0.bias', 'module.transformer.3.attention.2.row_embedding.1.layer_norm.weight', 'module.transformer.3.attention.2.row_embedding.1.layer_norm.bias', 'module.transformer.3.attention.2.row_embedding.3.weight', 'module.transformer.3.attention.2.row_embedding.3.bias', 'module.transformer.3.attention.2.col_embedding.0.weight', 'module.transformer.3.attention.2.col_embedding.0.bias', 'module.transformer.3.attention.2.col_embedding.1.layer_norm.weight', 'module.transformer.3.attention.2.col_embedding.1.layer_norm.bias', 'module.transformer.3.attention.2.col_embedding.3.weight', 'module.transformer.3.attention.2.col_embedding.3.bias', 'module.transformer.3.attention.2.group_embedding.weight', 'module.transformer.3.attention.2.query.weight', 'module.transformer.3.attention.2.query.bias', 'module.transformer.3.attention.2.key.weight', 'module.transformer.3.attention.2.key.bias', 'module.transformer.3.attention.2.value.weight', 'module.transformer.3.attention.2.value.bias', 'module.transformer.3.attention.2.wout.weight', 'module.transformer.3.attention.2.wout.bias', 'module.transformer.3.attention.3.layer_norm.weight', 'module.transformer.3.attention.3.layer_norm.bias', 'module.transformer.3.mlp.0.weight', 'module.transformer.3.mlp.0.bias', 'module.transformer.3.mlp.1.layer_norm.weight', 'module.transformer.3.mlp.1.layer_norm.bias', 'module.transformer.3.mlp.3.weight', 'module.transformer.3.mlp.3.bias', 'module.transformer.3.mlp.4.layer_norm.weight', 'module.transformer.3.mlp.4.layer_norm.bias', 'module.transformer.4.attention.0.layer_norm.weight', 'module.transformer.4.attention.0.layer_norm.bias', 'module.transformer.4.attention.2.row_indices', 'module.transformer.4.attention.2.col_indices', 'module.transformer.4.attention.2.g_indices', 'module.transformer.4.attention.2.group._identity', 'module.transformer.4.attention.2.group._elements', 'module.transformer.4.attention.2.group._relative_positions', 'module.transformer.4.attention.2.row_embedding.0.weight', 'module.transformer.4.attention.2.row_embedding.0.bias', 'module.transformer.4.attention.2.row_embedding.1.layer_norm.weight', 'module.transformer.4.attention.2.row_embedding.1.layer_norm.bias', 'module.transformer.4.attention.2.row_embedding.3.weight', 'module.transformer.4.attention.2.row_embedding.3.bias', 'module.transformer.4.attention.2.col_embedding.0.weight', 'module.transformer.4.attention.2.col_embedding.0.bias', 'module.transformer.4.attention.2.col_embedding.1.layer_norm.weight', 'module.transformer.4.attention.2.col_embedding.1.layer_norm.bias', 'module.transformer.4.attention.2.col_embedding.3.weight', 'module.transformer.4.attention.2.col_embedding.3.bias', 'module.transformer.4.attention.2.group_embedding.weight', 'module.transformer.4.attention.2.query.weight', 'module.transformer.4.attention.2.query.bias', 'module.transformer.4.attention.2.key.weight', 'module.transformer.4.attention.2.key.bias', 'module.transformer.4.attention.2.value.weight', 'module.transformer.4.attention.2.value.bias', 'module.transformer.4.attention.2.wout.weight', 'module.transformer.4.attention.2.wout.bias', 'module.transformer.4.attention.3.layer_norm.weight', 'module.transformer.4.attention.3.layer_norm.bias', 'module.transformer.4.mlp.0.weight', 'module.transformer.4.mlp.0.bias', 'module.transformer.4.mlp.1.layer_norm.weight', 'module.transformer.4.mlp.1.layer_norm.bias', 'module.transformer.4.mlp.3.weight', 'module.transformer.4.mlp.3.bias', 'module.transformer.4.mlp.4.layer_norm.weight', 'module.transformer.4.mlp.4.layer_norm.bias', 'module.transformer.5.attention.0.layer_norm.weight', 'module.transformer.5.attention.0.layer_norm.bias', 'module.transformer.5.attention.2.row_indices', 'module.transformer.5.attention.2.col_indices', 'module.transformer.5.attention.2.g_indices', 'module.transformer.5.attention.2.group._identity', 'module.transformer.5.attention.2.group._elements', 'module.transformer.5.attention.2.group._relative_positions', 'module.transformer.5.attention.2.row_embedding.0.weight', 'module.transformer.5.attention.2.row_embedding.0.bias', 'module.transformer.5.attention.2.row_embedding.1.layer_norm.weight', 'module.transformer.5.attention.2.row_embedding.1.layer_norm.bias', 'module.transformer.5.attention.2.row_embedding.3.weight', 'module.transformer.5.attention.2.row_embedding.3.bias', 'module.transformer.5.attention.2.col_embedding.0.weight', 'module.transformer.5.attention.2.col_embedding.0.bias', 'module.transformer.5.attention.2.col_embedding.1.layer_norm.weight', 'module.transformer.5.attention.2.col_embedding.1.layer_norm.bias', 'module.transformer.5.attention.2.col_embedding.3.weight', 'module.transformer.5.attention.2.col_embedding.3.bias', 'module.transformer.5.attention.2.group_embedding.weight', 'module.transformer.5.attention.2.query.weight', 'module.transformer.5.attention.2.query.bias', 'module.transformer.5.attention.2.key.weight', 'module.transformer.5.attention.2.key.bias', 'module.transformer.5.attention.2.value.weight', 'module.transformer.5.attention.2.value.bias', 'module.transformer.5.attention.2.wout.weight', 'module.transformer.5.attention.2.wout.bias', 'module.transformer.5.attention.3.layer_norm.weight', 'module.transformer.5.attention.3.layer_norm.bias', 'module.transformer.5.mlp.0.weight', 'module.transformer.5.mlp.0.bias', 'module.transformer.5.mlp.1.layer_norm.weight', 'module.transformer.5.mlp.1.layer_norm.bias', 'module.transformer.5.mlp.3.weight', 'module.transformer.5.mlp.3.bias', 'module.transformer.5.mlp.4.layer_norm.weight', 'module.transformer.5.mlp.4.layer_norm.bias', 'module.transformer.6.weight'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.GroupTransformer(\n",
    "    group=groups.E2(num_elements=8),\n",
    "    in_channels=1,\n",
    "    num_channels=20,\n",
    "    block_sizes=[2, 3],\n",
    "    expansion_per_block=1,\n",
    "    crop_per_layer=[2, 0, 2, 1, 1],\n",
    "    image_size=28,\n",
    "    num_classes=2,\n",
    "    dropout_rate_after_maxpooling=0.0,\n",
    "    maxpool_after_last_block=False,\n",
    "    normalize_between_layers=False,\n",
    "    patch_size=5,\n",
    "    num_heads=9,\n",
    "    norm_type=\"LayerNorm\",\n",
    "    activation_function=\"Swish\",\n",
    "    attention_dropout_rate=0.1,\n",
    "    value_dropout_rate=0.1,\n",
    "    whitening_scale=1.41421356,\n",
    ")\n",
    "model_path = \"../saved/rotMNIST_model_p4msa_type_Local_patch_5_dpatt_0.1_dpval_0.1_activ_Swish_norm_LayerNorm_white_1.41421356_optim_Adam_lr_0.001_bs_16_ep_50_wd_0.0001_seed_0_sched_constants_schdec_1.0.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = (0.1307,)\n",
    "data_stddev = (0.3081,)\n",
    "transform_test = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(data_mean, data_stddev),\n",
    "    ]\n",
    ")\n",
    "test_set = MNIST_rot(root=\"../data\", stage=\"test\", download=True, transform=transform_test, data_fraction=1, only_3_and_8=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 with probability 0.9998062252998352\n"
     ]
    }
   ],
   "source": [
    "idx_2_target = {\n",
    "    0: 3,\n",
    "    1: 8\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    example_image, example_idx = next(iter(test_loader))\n",
    "    out = model(example_image)\n",
    "    example_image = example_image.squeeze()  # Batch dimension\n",
    "    print(f\"Target: {idx_2_target[example_idx.item()]}\")\n",
    "    plt.imshow(example_image.cpu().numpy(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    _, preds = torch.max(out, 1)\n",
    "    print(f\"{idx_2_target[preds.item()]} with probability {torch.softmax(out, dim=1)[0][preds].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo visualize attention and all the different layers\n",
    "# just a bunch of explainability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
