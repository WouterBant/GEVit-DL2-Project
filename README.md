# E(2) (Post-Hoc) Equivariant (Attention) Models for Image Classification 

### Wouter Bant, Colin Bot, Jasper Eppink, Clio Feng, Floris Six Dijkstra

Inspired by the equivariant attention model present in [Group Equivariant Vision Transformer](https://openreview.net/forum?id=uVG_7x41bN),  UAI 2023, we conduct experiments to validate the performance of the presented model. Furthermore, we present and evaluate several ways of making non-equivariant models equivariant by test time augmentations. Building on the GE-ViT, we make the modern ViT equivariant. Also, we provide many visualizations for a better understanding of GE-ViTs and other presented methods.

### Acknowledgements
This repository contains the source code accompanying the paper: [Group Equivariant Vision Transformer](https://openreview.net/forum?id=uVG_7x41bN),  UAI 2023.

The original code, containing a small error, is from the [GSA-Nets](https://openreview.net/forum?id=JkfYjnOEo6M) paper by David W. Romero and Jean-Baptiste Cordonnier.
