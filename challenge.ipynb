{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKpitc-Cm_IJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WouterBant/GEVit-DL2-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GEVit-DL2-Project/"
      ],
      "metadata": {
        "id": "T1tNdHhQnBrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install wandb\n",
        "!pip install ml_collections"
      ],
      "metadata": {
        "id": "Vvt4W7i3ni7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from datasets import MNIST_rot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import models\n",
        "import torch\n",
        "import g_selfatt.groups as groups\n",
        "import models\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ],
      "metadata": {
        "id": "Su51Tu9OnCTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_mean = (0.1307,)\n",
        "data_stddev = (0.3081,)\n",
        "transform_train = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(data_mean, data_stddev),\n",
        "    ]\n",
        ")\n",
        "transform_test = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(data_mean, data_stddev),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ocl6C1lPnV0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = MNIST_rot(root=\"./data\", stage=\"train\", download=True, transform=transform_train, data_fraction=1)\n",
        "evaluation_set = MNIST_rot(root=\"./data\", stage=\"validation\", download=True, transform=transform_train, data_fraction=1)\n",
        "test_set = MNIST_rot(root=\"./data\", stage=\"test\", download=True, transform=transform_test, data_fraction=1)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(\n",
        "    training_set,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "evaluation_loader = torch.utils.data.DataLoader(\n",
        "    evaluation_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "metadata": {
        "id": "5sFvl7w2qWBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate some little training procedure to investigate speed of different parts of the codebase\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.GroupTransformer(\n",
        "            group=groups.SE2(num_elements=4),\n",
        "            in_channels=1,\n",
        "            num_channels=20,\n",
        "            block_sizes=[2, 3],\n",
        "            expansion_per_block=1,\n",
        "            crop_per_layer=[2, 0, 2, 1, 1],\n",
        "            image_size=28,\n",
        "            num_classes=10,\n",
        "            dropout_rate_after_maxpooling=0.0,\n",
        "            maxpool_after_last_block=False,\n",
        "            normalize_between_layers=False,\n",
        "            patch_size=5,\n",
        "            num_heads=9,\n",
        "            norm_type=\"LayerNorm\",\n",
        "            activation_function=\"Swish\",\n",
        "            attention_dropout_rate=0.1,\n",
        "            value_dropout_rate=0.1,\n",
        "            whitening_scale=1.41421356,\n",
        "        )\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "hQse7spCqZHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "iwYUu_51xevJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets try lr = 0.1, this is a really small model!!\n",
        "# also who uses swish, lets also try relu later (or does this break equivariance?)\n",
        "# it should be possible to train in less than 5 epochs\n",
        "# i set epochs to 4 so be patient with judging the loss\n",
        "# target loss: 0.2 (with normal run achieved after 50 epochs)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for inputs, labels in training_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            with autocast():\n",
        "                out = model(inputs)\n",
        "                loss = criterion(out, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            print(loss.item())\n",
        "\n",
        "# first run with lr = 0.1 doesn't seem to be too high\n",
        "# might even try higher, also don't forget to experiment with relu"
      ],
      "metadata": {
        "id": "SY6ApuvnqnZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = total = 0\n",
        "\n",
        "model.eval()\n",
        "for inputs, labels in training_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "            with autocast():\n",
        "                out = model(inputs)\n",
        "    _, preds = torch.max(out, 1)\n",
        "    correct += (preds == labels).sum().item()\n",
        "    total += labels.size(0)\n",
        "\n",
        "correct / total"
      ],
      "metadata": {
        "id": "f4UQbSX3qpnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}