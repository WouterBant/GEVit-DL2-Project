{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import correct path\n",
    "import os,sys\n",
    "g_selfatt_source =  os.path.join(os.getcwd(), '..')\n",
    "if g_selfatt_source not in sys.path:\n",
    "    sys.path.append(g_selfatt_source)\n",
    "    \n",
    "g_selfatt_source_2 = os.path.join(g_selfatt_source, 'src')\n",
    "if g_selfatt_source_2 not in sys.path:\n",
    "    sys.path.append(g_selfatt_source_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from datasets import MNIST_rot\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image, ImageOps\n",
    "import models\n",
    "import g_selfatt.groups as groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a dataloader with batchsize one\n",
    "data_mean = (0.1307,)\n",
    "data_stddev = (0.3081,)\n",
    "transform_test = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(data_mean, data_stddev),\n",
    "    ]\n",
    ")\n",
    "test_set = MNIST_rot(root=\"../data\", stage=\"train\", download=True, transform=transform_test, data_fraction=1, only_3_and_8=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get one data image and push it through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/jasper/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Get datapoint\n",
    "data = iter(test_loader)\n",
    "for _ in range(19): #Cherry picked the 12th image\n",
    "    image, idx = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = image.squeeze()  # Batch dimension\n",
    "plt.imshow(image.cpu().numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory is /Users/jasper/Library/CloudStorage/GoogleDrive-jasper.eppink@gmail.com/My Drive/Documents/school/Master/AI/Jaar 1/Deep Learning 2/Project/Project git MAIN/GEVit-DL2-Project/demos\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.lifting_self_attention.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.lifting_self_attention.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.lifting_self_attention.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.lifting_self_attention.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.lifting_self_attention.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.0.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.0.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.0.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.0.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.1.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.1.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.1.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.1.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.1.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.1.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.1.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.3.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.3.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.3.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.3.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.3.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.3.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.3.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.4.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.4.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.4.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.4.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.4.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.4.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.4.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.5.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.5.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.5.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.5.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.5.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.5.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.5.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(model)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MAIN_environment/lib/python3.8/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.lifting_self_attention.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.lifting_self_attention.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.lifting_self_attention.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.lifting_self_attention.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.lifting_self_attention.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.0.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.0.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.0.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.0.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.0.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.1.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.1.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.1.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.1.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.1.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.1.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.1.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.3.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.3.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.3.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.3.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.3.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.3.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.3.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.4.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.4.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.4.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.4.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.4.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.4.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.4.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4]).\n\tsize mismatch for module.transformer.5.attention.2.row_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.5.attention.2.col_indices: copying a param with shape torch.Size([4, 5, 5]) from checkpoint, the shape in current model is torch.Size([8, 5, 5]).\n\tsize mismatch for module.transformer.5.attention.2.g_indices: copying a param with shape torch.Size([4, 4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8, 8]).\n\tsize mismatch for module.transformer.5.attention.2.group._identity: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).\n\tsize mismatch for module.transformer.5.attention.2.group._elements: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([8, 2]).\n\tsize mismatch for module.transformer.5.attention.2.group._relative_positions: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 8]).\n\tsize mismatch for module.transformer.5.attention.2.group_embedding.weight: copying a param with shape torch.Size([4, 4]) from checkpoint, the shape in current model is torch.Size([8, 4])."
     ]
    }
   ],
   "source": [
    "# Now import GE-ViT of the models and run it on the image\n",
    "model = models.GroupTransformer(\n",
    "    group=groups.E2(num_elements=8),\n",
    "    in_channels=1,\n",
    "    num_channels=20,\n",
    "    block_sizes=[2, 3],\n",
    "    expansion_per_block=1,\n",
    "    crop_per_layer=[2, 0, 2, 1, 1],\n",
    "    image_size=28,\n",
    "    num_classes=10,\n",
    "    dropout_rate_after_maxpooling=0.0,\n",
    "    maxpool_after_last_block=False,\n",
    "    normalize_between_layers=False,\n",
    "    patch_size=5,\n",
    "    num_heads=9,\n",
    "    norm_type=\"LayerNorm\",\n",
    "    activation_function=\"Swish\",\n",
    "    attention_dropout_rate=0.1,\n",
    "    value_dropout_rate=0.1,\n",
    "    whitening_scale=1.41421356,\n",
    ")\n",
    "print(f\"The working directory is {os.getcwd()}\")\n",
    "model_path = \"Checkpoints_visualisations_rotations/rotMNIST_model_p4sa_type_Local_patch_5_dpatt_0.1_dpval_0.1_activ_Swish_norm_LayerNorm_white_1.41421356_optim_Adam_lr_0.0005_bs_64_ep_500_wd_0.0001_seed_0_sched_constants_schdec_1.0.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normal vision transformer\n",
    "model = VisionTransformer(embed_dim=64,\n",
    "                        hidden_dim=512,\n",
    "                        num_heads=4,\n",
    "                        num_layers=6,\n",
    "                        patch_size=4,\n",
    "                        num_channels=1,\n",
    "                        num_patches=49,\n",
    "                        num_classes=10,\n",
    "                        dropout=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, degree, show=False):\n",
    "    \"\"\" Returns all transformations of the input images \"\"\"\n",
    "    # First change image from tensor to PIL\n",
    "    image = image.squeeze()\n",
    "    image = image.cpu().numpy()\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    transform = TF.rotate(image, degree)\n",
    "\n",
    "    # Now convert back to tensor\n",
    "    transform = TF.to_tensor(transform)\n",
    "    transform = transform.squeeze()\n",
    "    if show:\n",
    "        plt.imshow(transform.cpu().numpy(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return transform  # C, H, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now create the visualisation of the digit with the slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "#!conda install jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.widgets import Button, Slider\n",
    "\n",
    "# The image I want to show rotated is image, now I want to create a slider that rotates the image\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "degree = 0\n",
    "rotated_image = rotate_image(image, degree)\n",
    "image_plot = ax.imshow(rotated_image.cpu().numpy(), cmap=\"gray\")\n",
    "ax.set_title(\"Degree: {}\".format(degree))\n",
    "\n",
    "# Define the slider update function\n",
    "def update_rotation(val):\n",
    "    degree = val\n",
    "    rotated_image = rotate_image(image, degree)\n",
    "    image_plot.set_data(rotated_image.cpu().numpy())\n",
    "    ax.set_title(\"Degree: {}\".format(degree))\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Create the slider\n",
    "slider_ax = plt.axes([0.2, 0.1, 0.6, 0.03])\n",
    "slider = Slider(slider_ax, 'Rotation', -180, 180, valinit=degree)\n",
    "slider.on_changed(update_rotation)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
