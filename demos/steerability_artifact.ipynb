{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import g_selfatt.groups as groups\n",
    "import torch\n",
    "import models\n",
    "from g_selfatt.utils import num_params\n",
    "import torch\n",
    "import torchvision\n",
    "from datasets import MNIST_rot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import models\n",
    "import torch\n",
    "import g_selfatt.groups as groups\n",
    "import models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(image, n_rotations=4, flips=True):\n",
    "    transforms = [image]\n",
    "\n",
    "    # Rotations\n",
    "    for i in range(1, n_rotations):\n",
    "        angle = i * (360 / n_rotations)\n",
    "        rotated_image = TF.rotate(image, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "        transforms.append(rotated_image)\n",
    "\n",
    "    # Flips\n",
    "    if flips:\n",
    "        flips = []\n",
    "        for transform in transforms:\n",
    "            flipped_image_lr = TF.hflip(transform)\n",
    "            flips.append(flipped_image_lr)\n",
    "\n",
    "        transforms.extend(flips)\n",
    "        \n",
    "    res = torch.cat(transforms)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GroupTransformer(\n",
    "    group=groups.SE2(num_elements=8),  # note 8 rotations\n",
    "    in_channels=1,\n",
    "    num_channels=20,\n",
    "    block_sizes=[2],\n",
    "    expansion_per_block=1,\n",
    "    crop_per_layer=[2, 0],\n",
    "    image_size=28,\n",
    "    num_classes=2,\n",
    "    dropout_rate_after_maxpooling=0.0,\n",
    "    maxpool_after_last_block=False,\n",
    "    normalize_between_layers=False,\n",
    "    patch_size=5,\n",
    "    num_heads=9,\n",
    "    norm_type=\"LayerNorm\",\n",
    "    activation_function=\"Swish\",\n",
    "    attention_dropout_rate=0.1,\n",
    "    value_dropout_rate=0.1,\n",
    "    whitening_scale=1.41421356,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = torchvision.transforms.ToTensor()\n",
    "test_set = MNIST_rot(root=\"../data\", stage=\"test\", download=True, transform=transform_test, data_fraction=1, only_3_and_8=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(test_loader)\n",
    "image, target = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "transforms = get_transforms(image, n_rotations=8, flips=False)\n",
    "logits = model(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "logits = logits\n",
    "transforms = get_transforms(image, n_rotations=8, flips=False)\n",
    "transforms = transforms\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "for i in range(8):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(transforms[i, 0], cmap='gray')\n",
    "    ax.set_title(f\"Logits: {logits[i].detach().cpu().numpy()}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
